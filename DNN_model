import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import LearningRateScheduler
from sklearn.model_selection import train_test_split
import numpy as np
import glob

# 载入所有txt文件路径
file_pattern = 'path_to_your_txt_files/*.txt'  # 替换为你的txt文件路径模式
txt_files = glob.glob(file_pattern)

# 超参数
initial_learning_rate = 0.001
epochs = 100
warmup_epochs = 10
decay_rate = 0.1
batch_size = 32  # 每批次加载的样本数

# 自定义学习率调度函数
def scheduler(epoch, lr):
    if epoch < warmup_epochs:
        return initial_learning_rate * (epoch + 1) / warmup_epochs
    else:
        return initial_learning_rate * decay_rate ** ((epoch - warmup_epochs) / (epochs - warmup_epochs))

# 创建生成器函数
def data_generator(txt_files, batch_size):
    while True:
        for file in txt_files:
            data_part = np.loadtxt(file)  # 加载部分数据
            X = data_part[:, :-1]  # 假设最后一列是标签
            y = data_part[:, -1]
            num_batches = len(X) // batch_size

            for i in range(num_batches):
                start_idx = i * batch_size
                end_idx = (i + 1) * batch_size
                yield X[start_idx:end_idx], y[start_idx:end_idx]

# 创建DNN模型
model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(64, activation='relu'),
    Dense(1, activation='sigmoid')  # 二元分类，使用sigmoid作为输出激活函数
])

# 编译模型
optimizer = Adam()
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# 学习率调度回调
lr_scheduler = LearningRateScheduler(scheduler)

# 训练模型（使用生成器）
num_samples = sum(len(np.loadtxt(file)) for file in txt_files)
steps_per_epoch = num_samples // batch_size

model.fit(data_generator(txt_files, batch_size), epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=[lr_scheduler])
